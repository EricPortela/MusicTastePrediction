{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "training = pd.read_csv('training_data.csv', sep=',')\n",
    "test = pd.read_csv('songs_to_classify.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only use five features version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which features to use\n",
    "features = ['danceability','key','loudness','instrumentalness','liveness']\n",
    "\n",
    "# i learn how to do one-hot encode from chatgpt because i realized there is no size meaning in the key feature.  \n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "X_train_selected = training[features]\n",
    "X_test_selected = test[features]\n",
    "# OneHotEncode the 'key' feature \n",
    "X_train_key_encoded = encoder.fit_transform(X_train_selected[['key']])\n",
    "X_test_key_encoded = encoder.transform(X_test_selected[['key']])\n",
    "\n",
    "X_train_no_key = X_train_selected.drop('key', axis=1).values\n",
    "X_test_no_key = X_test_selected.drop('key', axis=1).values\n",
    "\n",
    "X_train = np.hstack([X_train_no_key, X_train_key_encoded])\n",
    "X_test = np.hstack([X_test_no_key, X_test_key_encoded])\n",
    "\n",
    "# extract labels\n",
    "y_train = training.loc[:, 'label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "X_trainn = X_train * 1 / np.max(np.abs(X_train), axis=0)\n",
    "X_testn = X_test * 1 / np.max(np.abs(X_test), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using all features version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i learned how to choose all the features from chatgpt but now i think i could figure it out myself\n",
    "\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "#X_train_key_encoded = encoder.fit_transform(X_train_selected[['key']])\n",
    "#X_test_key_encoded = encoder.transform(X_test_selected[['key']])\n",
    "\n",
    "# Remove the 'key' column and keep other features\n",
    "#X_train_no_key_time = training.loc[:, training.columns != 'key'].drop('label', axis=1).values\n",
    "#X_test_no_key_time = test.loc[:, test.columns != 'key'].values\n",
    "\n",
    "# Merge OneHot encoded 'key' with other features\n",
    "#X_train = np.hstack([X_train_no_key_time, X_train_key_encoded, X_train_time_signature_encoded])\n",
    "#X_test = np.hstack([X_test_no_key_time, X_test_key_encoded, X_test_time_signature_encoded])\n",
    "\n",
    "# Extract labels\n",
    "#y_train = training.loc[:, 'label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random forest model\n",
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "# i use chatgpt to generate this code for choosing these hyperparameters using GridSearchCV. \n",
    "# I know this method but i was not sure how to implement it in code.\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                               scoring='accuracy', cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Train the model using GridSearchCV\n",
    "grid_search_rf.fit(X=X_trainn, y=y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f'Best parameters for Random Forest: {best_params_rf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00010001001101001011001010000010111111010001100110001101100011000111100001010110110101100000001111110010000011110010110001101110100111111101101110001011101111111101100100101000001001111100100000100111\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best model\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "# Chagpt designed this output format for me and i asked it to remove spaces between elements so that i could use it for submission\n",
    "predictions_rf = best_rf_model.predict(X=X_testn).reshape(-1, 1).astype(int).reshape(1, -1)\n",
    "#print(predictions_rf)\n",
    "# Convert an array to a string and remove spaces between elements\n",
    "print(''.join(map(str, predictions_rf.flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest cross-validation accuracy: 0.7440 ± 0.0288\n"
     ]
    }
   ],
   "source": [
    "# i use chatgpt to do cross validation because I need a standard to evaluate the pros and cons of different models\n",
    "cv_scores_rf = cross_val_score(best_rf_model, X_trainn, y_train, cv=5, scoring='accuracy')\n",
    "print(f'Random Forest cross-validation accuracy: {cv_scores_rf.mean():.4f} ± {cv_scores_rf.std():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
